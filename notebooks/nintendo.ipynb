{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93663f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logic to get all pages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import re\n",
    "from time import sleep\n",
    "import csv\n",
    "\n",
    "\n",
    "url = 'https://www.mobygames.com/game/'\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69c95aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996\n"
     ]
    }
   ],
   "source": [
    "# The \"Next\" button will eventually disappear because Mobygames impose restrictions on bots, guest users, non-premium users, etc.\n",
    "game_urls = set()\n",
    "while True:\n",
    "    try:\n",
    "        game_cols = driver.find_elements(By.CSS_SELECTOR, \"td\")\n",
    "        for col in game_cols:\n",
    "            try:\n",
    "                link = col.find_element(By.CLASS_NAME, \"me-1\").get_attribute(\"href\")\n",
    "                game_urls.add(link)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        next_button = driver.find_element(By.XPATH, \"//a[text()='Next']\")\n",
    "\n",
    "        # Wait until the next button is clickable\n",
    "        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//a[text()='Next']\")))\n",
    "\n",
    "        # Use ActionChains to move to and click the button\n",
    "        ActionChains(driver).move_to_element(next_button).click().perform()\n",
    "        \n",
    "    except Exception as e:\n",
    "        break\n",
    "game_urls = list(game_urls)\n",
    "print(len(game_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1498295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details: Scraped on each individual game's page\n",
    "def get_details(soup):\n",
    "    # Get title\n",
    "    title_div = soup.find(\"h1\", class_=\"mb-0\")\n",
    "    title = title_div.text\n",
    "    \n",
    "    details = {}\n",
    "    details[\"Title\"] = title\n",
    "    keys = [\"Publishers\", \"Developers\", \"Released\", \"Genre\", \"Perspective\", \"Visual\", \"Art\", \"Gameplay\", \"Interface\"]\n",
    "    for key in keys:\n",
    "        element = soup.find(\"dt\", string=key)\n",
    "        if element is not None:\n",
    "            text = element.find_next(\"dd\").text\n",
    "            # Remove newlines and extra spaces\n",
    "            cleaned_text = re.sub(r'\\s+', ' ', text).strip()\n",
    "            details[key] = cleaned_text\n",
    "    \n",
    "    return details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0bcac578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playe: Scraped on each individual game's page\n",
    "def get_player_reviews(soup):\n",
    "    player_reviews_div = soup.find(\"div\", id=\"players\")\n",
    "    player_reviews = player_reviews_div.find_all(\"div\", class_=\"border mb\")\n",
    "    \n",
    "    final_reviews = []\n",
    "    for review in player_reviews:\n",
    "        stars = review.find_all(\"span\", class_=\"stars stars-sm\", style=True)\n",
    "        for star in stars:\n",
    "            style = star[\"style\"]\n",
    "            style_dict = dict(item.split(\":\") for item in style.split(\";\") if item)\n",
    "            rating = style_dict.get(\"--rating\")\n",
    "            try:\n",
    "                final_reviews.append(float(rating))\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "    return final_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "12376265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critics Reviews: These are scraped at the homepage!!!!\n",
    "\n",
    "def get_critic_reviews(soup):\n",
    "    critics_reviews_tag = soup.find(\"critic-reviews\")\n",
    "    final_critics = []\n",
    "    a = 0\n",
    "    if critics_reviews_tag:\n",
    "        reviews_attr = critics_reviews_tag.get(\":reviews\")\n",
    "\n",
    "        if reviews_attr:\n",
    "            try:\n",
    "                reviews = json.loads(reviews_attr)\n",
    "                for review in reviews:\n",
    "                    score = review['normalized_score']\n",
    "                    try:\n",
    "                        final_critics.append(int(round(score)))\n",
    "                        a += 1\n",
    "                    except TypeError as e:\n",
    "                        continue\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "    else:\n",
    "        print(\"No <critic-reviews> tag found.\")\n",
    "    return final_critics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7eba1da4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No <critic-reviews> tag found.\n",
      "No <critic-reviews> tag found.\n",
      "No <critic-reviews> tag found.\n",
      "No <critic-reviews> tag found.\n",
      "No <critic-reviews> tag found.\n",
      "No <critic-reviews> tag found.\n",
      "No <critic-reviews> tag found.\n",
      "No <critic-reviews> tag found.\n",
      "No <critic-reviews> tag found.\n",
      "No <critic-reviews> tag found.\n",
      "No <critic-reviews> tag found.\n",
      "No <critic-reviews> tag found.\n"
     ]
    }
   ],
   "source": [
    "# Open CSV file and write header\n",
    "with open('game_reviews_23.csv', mode='a', newline='', encoding='utf-8') as output_file:\n",
    "    gamereviews_csv = csv.writer(output_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    # Write header only once\n",
    "    if output_file.tell() == 0:\n",
    "        gamereviews_csv.writerow(['platform', 'title', 'url', 'published_by', 'developed_by', \n",
    "                                 'released', 'genre', 'perspective', 'visual', 'art', 'gameplay', 'interface',\n",
    "                                 'user_reviews', 'user_review_count', 'average_user_review',\n",
    "                                 'critic_reviews', 'critic_review_count', 'average_critic_review'])\n",
    "\n",
    "    # Loop through game URLs\n",
    "    for url in game_urls:\n",
    "        driver.get(url)\n",
    "        try:\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            details = get_details(soup)\n",
    "            critic_reviews = get_critic_reviews(soup)\n",
    "\n",
    "            # Go to reviews URL\n",
    "            reviews_url = f\"{driver.current_url}/reviews/\"\n",
    "            driver.get(reviews_url)\n",
    "            reviews_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            player_reviews = get_player_reviews(reviews_soup)\n",
    "\n",
    "            # Extract details for CSV\n",
    "            platform = 'SNES'\n",
    "            title = details.get('Title', '')  # Ensure 'Title' is a key in your details\n",
    "            published_by = details.get('Publishers', '')\n",
    "            developed_by = details.get('Developers', '')\n",
    "            released = details.get('Released', '')\n",
    "            genre = details.get('Genre', '')\n",
    "            perspective = details.get('Perspective', '')\n",
    "            visual = details.get('Visual', '')\n",
    "            art = details.get('Art', '')\n",
    "            gameplay = details.get('Gameplay', '')\n",
    "            interface = details.get('Interface', '')\n",
    "\n",
    "            # Ccalculate review counts and averages\n",
    "            user_review_count = len(player_reviews)  \n",
    "            average_review = sum(player_reviews) / user_review_count if user_review_count > 0 else 0\n",
    "\n",
    "            critic_count = len(critic_reviews)  \n",
    "            average_critic = sum(critic_reviews) / critic_count if critic_count > 0 else 0\n",
    "\n",
    "            # Write data to CSV\n",
    "            gamereviews_csv.writerow([platform, title, url, published_by, developed_by,\n",
    "                                     released, genre, perspective, visual, art, gameplay, interface,\n",
    "                                     player_reviews, user_review_count, average_review,\n",
    "                                     critic_reviews, critic_count, average_critic])\n",
    "\n",
    "        except AttributeError as e:\n",
    "            continue\n",
    "        \n",
    "        # Go back to the main page\n",
    "        driver.back()\n",
    "\n",
    "driver.close()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
